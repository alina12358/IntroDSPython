{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 5 - Pandas\n",
    "\n",
    "Pandas es una librería escrita sobre `Python` para la manipulación y el análisis de datos. En particular, ofrece estructuras de datos y operaciones para manipular tablas numéricas y series temporales. El nombre deriva del término \"datos de panel\", un término de econometría para los conjuntos de datos que incluyen observaciones durante múltiples períodos de tiempo para los mismos individuos.\n",
    "\n",
    "Algunas de las herramientas fundamentales de esta librería son:\n",
    "\n",
    "- Creación de un objeto \"DataFrame\" para la manipulación de datos con indexación integrada.\n",
    "- Herramientas para leer y escribir entre estructuras de datos en memoria y diferentes formatos de archivo.\n",
    "- Alineación de datos y manejo integrado de datos faltantes.\n",
    "- Inserción y eliminación de columnas en la estructura de datos.\n",
    "- Motor de agrupación que permite realizar operaciones de división-aplicación-combinación en conjuntos de datos.\n",
    "- Fusión y unión de conjuntos de datos.\n",
    "- Indexación jerárquica de ejes para trabajar con datos de alta dimensión en una estructura de datos de baja dimensión.\n",
    "- Funcionalidad de series temporales: Generación de rangos de fechas y conversiones de frecuencias, estadísticas de ventana móvil, regresiones lineales de ventana móvil, desplazamiento de fechas y desfase.\n",
    "- Proporciona filtrado de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "Una serie es una matriz unidimensional etiquetada capaz de contener cualquier tipo de datos (enteros, cadenas, números de punto flotante, objetos de Python, etc.). Las etiquetas de los ejes se denominan índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 3, 5, 6, 8]) # El primer objeto de Pandas que veremos es una serie, observa que en su forma\n",
    "                               # más simple es muy parecida a un vector de NumPy, sin embargo, está indexada.\n",
    "print(s,'\\n')\n",
    "\n",
    "# Otra forma de definir una serie es mediante un diccionario\n",
    "\n",
    "s = pd.Series({\"b\": 1, \"a\": 0, \"c\": 2})\n",
    "print(s,'\\n')\n",
    "\n",
    "print(s['b'],'\\n') # Para accesar a un elemento se hace de la misma forma que en el resto de estructuras vistas.\n",
    "\n",
    "print(s.dtype,'\\n') # Con la función dtype se obtiene el tipo de datos contenido\n",
    "\n",
    "print(s.array,'\\n') # Arroja el vector que está contenido en la serie (sin el índice)\n",
    "\n",
    "print(s.to_numpy(),'\\n') # Lo mismo de arriba pero da como resultado un vector de NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones \n",
    "\n",
    "Cuando se trabaja con vectores de NumPy, no suele ser necesario hacer un ciclo valor a valor para hacer operaciones usuales. Lo mismo ocurre cuando se trabaja con Series en pandas. Las series también se pueden pasar a la mayoría de los métodos de NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s + s,'\\n') \n",
    "\n",
    "print(s * 3,'\\n') \n",
    "\n",
    "print(s / s,'\\n')  # Observa el resultado NaN, proveniente de la diviión por cero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame \n",
    "\n",
    "Un DataFrame es una estructura de datos bidimensional etiquetada, con columnas de tipos potencialmente diferentes. Se puede pensar en él como una hoja de cálculo de Excel, o como un diccionario de objetos Series. Generalmente es el objeto de pandas más utilizado. Al igual que las Series, los DataFrame aceptan muchos tipos diferentes de entradas:\n",
    "\n",
    "- Dict de ndarrays 1D, listas, dicts, o Series\n",
    "\n",
    "- 2-D numpy.ndarray\n",
    "\n",
    "- Ndarray estructurados o de registros\n",
    "\n",
    "- Una Serie\n",
    "\n",
    "- Otro DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción de un dataframe mediante series: \n",
    "\n",
    "d = {\"one\": pd.Series([1.0, 2.0, 3.0], index=[\"a\", \"b\", \"c\"]),            # Junto con los datos, se puede pasar opcionalmente\n",
    "    \"two\": pd.Series([1.0, 2.0, 3.0, 4.0], index=[\"a\", \"b\", \"c\", \"d\"]),}  #  argumentos de índices y nombre de columnas.\n",
    "\n",
    "df = pd.DataFrame(d) \n",
    "\n",
    "print(df,'\\n')\n",
    "\n",
    "# Construcción mediante un diccionario y vectores:\n",
    "\n",
    "d = {\"one\": [1.0, 2.0, 3.0, 4.0], \"two\": [4.0, 3.0, 2.0, 1.0]}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "print(df,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columnas, índices y elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns,'\\n') # Arroja un objeto de pandas, similar a una lista, con las columnas del dataframe\n",
    "\n",
    "print(df.index,'\\n') # Arroja un objeto de pandas, similar a una lista, con el índice del dataframe\n",
    "\n",
    "print(df['one'],'\\n') # Selecciona una columna\n",
    "\n",
    "df['three'] = df['one'] * df['two'] # Multiplica las columnas, para cualquier otra operación sólo se cambia el signo\n",
    "                                    # Definir una nueva columna de esta manera modifica directamente el dataframe\n",
    "print(df['three'],'\\n') # Selecciona una columna\n",
    "\n",
    "df['flag'] = df['three'] > 4 # Crea una columna booleana a partir de una condición\n",
    "\n",
    "print(df['flag'],'\\n')\n",
    "\n",
    "df['condition'] = df['three'][df['three'] > 4] # Y estas columnas booleanas se pueden utilizar para hacer otras columnas\n",
    "                                        # o dataframes con elementos del actual que cumplan la condición\n",
    "    \n",
    "print(df['condition'],'\\n')\n",
    "\n",
    "del df[\"flag\"]\n",
    "\n",
    "three = df.pop(\"three\") # Las columnas se pueden eliminar de la misma forma que en diccionarios\n",
    "\n",
    "print(df,'\\n')\n",
    "\n",
    "df[\"foo\"] = \"bar\"  # Al insertar un valor escalar, éste se propagará automáticamente para llenar la columna\n",
    "\n",
    "print(df,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loc y iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[1,'one'],'\\n') # .loc se usa para acceder a valores del dataframe, con filas y columnas \n",
    "print(df.loc[df['two'] > 2],'\\n') #  especificando la fila y columna, o mediante varibles booleanas \n",
    "\n",
    "# La función set_index se puede utilizar para definir el índice, nótese el uso del parámetro inplace, por defecto\n",
    "# tiene el valor False, cuando se establece en True, significa que el dataframe será modificado y la función no\n",
    "# tiene ninguna salida, esto se utiliza en muchas funciones que pueden modificar el dataframe.\n",
    "\n",
    "df.set_index(pd.Series(['a','b','c','d']), inplace=True)  \n",
    "\n",
    "print(df.loc['b':'c','one'],'\\n')   # Se toma de la fila \"b\" a la \"c\" y la columna \"one\" \n",
    "\n",
    "# iloc tiene una función muy similar, pero sólo toma índices enteros, es decir \n",
    "\n",
    "df.reset_index(drop=True,inplace=True) # esta función remueve el índice específico que habíamos definido, y con el\n",
    "                                       # parámetro drop en True, este se elimina del dataframe\n",
    "print(df,'\\n')\n",
    "\n",
    "print(df.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aritmética\n",
    "\n",
    "Los dataframes se pueden sumar, multiplicar etc., sin embargo, si tienen diferente tamaño, se rellenará automáticamente con \"NaN\".\n",
    "\n",
    "__Inténtelo usted__ cambia la operación aritmética más abajo y observa los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4), columns=[\"A\", \"B\", \"C\", \"D\"])\n",
    "df2 = pd.DataFrame(np.random.randn(7, 3), columns=[\"A\", \"B\", \"C\"])\n",
    "\n",
    "df + df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es posible hacer operaciones con una fila o columna y con escalares, esto no cambiará el tamaño o la estructura del dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df - df.iloc[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df * 5 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además se pueden usar funciones de NumPy sobre dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exponential: ','\\n',np.exp(df),'\\n')\n",
    "print('Log: ','\\n',np.log(df),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head, tail y describe\n",
    "\n",
    "Usualmente en Ciencia de Datos, los dataframes tienen una gran longitud, por lo que son útiles las funciones que muestran sólo una parte, o la descripción en términos estadísticos del mismo. Para esto tenemos algunas funciones fundamentales:\n",
    "- __head__: muestra la cantidad de filas del inicio que se especifique, por defecto 5\n",
    "- __tail__: muestra la cantidad de filas del final que se especifique, por defecto 5\n",
    "- __unique__: Se aplica a una serie, por ejemplo una columna del dataframe. Muestra los valores de la columna sin repetición.\n",
    "- __value_counts__: Se aplica a una serie, por ejemplo una columna del dataframe. Muestra los valores de la columna y su frecuencia, ordenados de mayor a menor.\n",
    "- __describe__: Muestra un resumen de las estadísticas descriptivas por columnas. Muestra (en orden), la cantidad de elementos, la media, la desviación estándar, el mínimo, máximo y los percentiles (cuartiles por defecto)  \n",
    "\n",
    "__Inténtelo usted__ Prueba a cambiar la cantidad de filas en \"head\" y \"tail\", y a seguir las instrucciones en la celda de \"describe\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # Cambia los percentiles pasando el parámetro percentiles=[0.05, 0.25, 0.75, 0.95], y prueba a cambiar estos valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join, Concatenate y Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat\n",
    "\n",
    "La función concat hace el trabajo de realizar operaciones de concatenación a lo largo de un eje mientras realiza una lógica de conjunto opcional (unión o intersección) de los índices (si los hay) en los otros ejes. Nótese que dice \"si hay\" porque sólo hay un único eje de concatenación posible para Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"]},\n",
    "                   index=[0, 1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({\"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n",
    "        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n",
    "        \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n",
    "        \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"]},index=[4, 5, 6, 7])\n",
    "\n",
    "df = pd.concat([df1,df2])\n",
    "\n",
    "print(df,'\\n')\n",
    "\n",
    "df = pd.concat([df1,df2],axis=1)  # Con el parámetro axis se puede escoger el eje a lo largo del cual concatenar\n",
    "                                  # por defecto es axis = 0.\n",
    "print(df,'\\n')                    # Nota que en este caso, como ninguno de los índices coincide, el dataframe se \n",
    "                                  # rellena con Nan automáticamente.\n",
    "\n",
    "\n",
    "# Cuando algunos de los índices (o columnas) coinciden y otros no, se puede escoger si se concatenan todos \n",
    "# los elementos, o sólo aquellos con índice (o columnas) coincidentes. El parámetro join hace este trabajo.\n",
    "\n",
    "df3 = pd.DataFrame({\"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n",
    "        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n",
    "        \"E\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n",
    "        \"F\": [\"D4\", \"D5\", \"D6\", \"D7\"]},index=[4, 5, 6, 7])\n",
    "\n",
    "df = pd.concat([df1,df3],join = 'inner') # Este es el valor por defecto, toma sólo las columnas (en este caso pues axis=0)\n",
    "                                         # coincidentes.\n",
    "\n",
    "print(df,'\\n')\n",
    "\n",
    "df = pd.concat([df1,df3],join = 'outer') # join='outer' une las columnas que coinciden, y mantiene las demás,  \n",
    "                                         # rellenando con Nan los elementos faltantes.\n",
    "print(df,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge \n",
    "\n",
    "pandas cuenta con operaciones de unión en memoria de alto rendimiento y muy similares a las bases de datos relacionales como SQL. pandas proporciona una función, merge(), para todas las operaciones estándar de unión de bases de datos entre objetos DataFrame o Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\"key\": [\"K0\", \"K1\", \"K2\", \"K3\"],\n",
    "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"]})\n",
    "\n",
    "right = pd.DataFrame({\"key\": [\"K0\", \"K1\", \"K2\", \"K3\"],\n",
    "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"]})\n",
    "\n",
    "df = pd.merge(left, right, on=\"key\")\n",
    "\n",
    "print(df,'\\n')\n",
    "\n",
    "# Si queremos unir los dataframes por columnas que no coinciden en nombre usamos los parámetros left_on y right_on\n",
    "# como en este caso no hay elementos coincidentes el dataframe resultante es vacío\n",
    "\n",
    "df = pd.merge(left, right, left_on=\"A\", right_on=\"C\")\n",
    "\n",
    "print(df,'\\n')\n",
    "\n",
    "# sin embargo podemos obtener resultados muy diferentes de acuerdo al tipo de unión que queremos, con el\n",
    "# parámetro \"how\" podemos cambiar por ejemplo a la unión de todos los elementos de ambos dataframes.\n",
    "\n",
    "df = pd.merge(left, right, left_on=\"A\", right_on=\"C\",how='outer')\n",
    "\n",
    "print(df,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Inténtelo usted__ Cambie el parámetro \"how\" por los valores en esta lista y vea el resultado. \n",
    "\n",
    " Método y descripción: \t\n",
    "\n",
    "- left: Utilizar sólo las llaves del dataframe izquierdo \n",
    "- right: Utilizar sólo las llaves del dataframe derecho \n",
    "- outer: Utiliza la unión de las llaves de ambos dataframe \t\n",
    "- inner: Utiliza la intersección de las llaves de ambos dataframe \t\n",
    "- cross: Crea el producto cartesiano de las filas de ambos dataframe \t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join\n",
    "\n",
    "join es un método conveniente si se quiere unir dos dataframes utilizando como llave el índice de cada uno. Esto podría hacerse con merge, transformando el índice en una columna, pero join proporciona un método directo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\"A\": [\"A0\", \"A1\", \"A2\"], \"B\": [\"B0\", \"B1\", \"B2\"]}, index=[\"K0\", \"K1\", \"K2\"])\n",
    "\n",
    "right = pd.DataFrame({\"C\": [\"C0\", \"C2\", \"C3\"], \"D\": [\"D0\", \"D2\", \"D3\"]}, index=[\"K0\", \"K2\", \"K3\"])\n",
    "\n",
    "df = left.join(right,how='inner') # Nuevamente, cambie el parámetro \"how\" para ver los diferentes resultados.\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar y crear archivos de datos\n",
    "\n",
    "Aunque hay muchos dataframes que podemos crear con pandas, usualmente esta librería se usa para tratar con datos existentes. Para ello existen funciones para leer gran variedad de datos. Veamos algunas con datos reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv \n",
    "\n",
    "Los archivos con extensión .csv (comma separated values) son de tipo texto cuyos valores están separados esencialmente por comas (aunque esto puede variar). Es de los formatos más usados para transmitir conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('directorio/nombre.csv') \n",
    "\n",
    "# print(df)\n",
    "\n",
    "# df.to_csv('directorio/nombre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### excel\n",
    "\n",
    "Otro tipo de archivo de datos (quizás el más popular) son los de extensión .xls o xlsx, usualmente llamados  hojas de cálculo de excel,    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel('directorio/nombre.xlsx') \n",
    "\n",
    "# print(df)\n",
    "\n",
    "# df.to_excel(directorio/nombre.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nota:__ A los pronombres \"read_\" para leer y \"to_\" para escribir se le pueden agregar las palabras claves del tipo de archivo (ej. stata, sas, spss, json, html, parquet, sql) para obtener las funciones adecuadas para cada tipo de archivo, la lista completa de los formatos aceptados puede ser consultada [aquí](https://pandas.pydata.org/docs/user_guide/io.html#).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos\n",
    "\n",
    "pandas tiene una gran cantidad de funcionalidades que no vamos a ver en este curso, si desea ampliar los conocimientos al respecto, en estos enlaces puede encontrar gran cantidad de información.\n",
    "\n",
    "- [Tutorial](https://pandas.pydata.org/docs/user_guide/basics.html)\n",
    "- [Trucos útiles](https://pandas.pydata.org/docs/user_guide/cookbook.html#cookbook)\n",
    "- [Tutorial interactivo](https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
